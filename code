import streamlit as st
import PyPDF2
from PyPDF2 import PdfReader
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.probability import FreqDist
from heapq import nlargest

# Download resources
nltk.download('punkt')
nltk.download('stopwords')

# Title of the app
st.title("PDF Summary Generator")

# File uploader widget
uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")

#if uploaded_file is not None:
  # Read the PDF file
  #pdf_reader = PyPDF2.PdfReader(uploaded_file)
if uploaded_file is not None:
  # Read the PDF file
  pdf_reader = PdfReader(uploaded_file)
  full_text = ""
  # Extract text from all pages
  for page in pdf_reader.pages:
    text = page.extract_text()
    if text:
      full_text += text

  # Display extracted text (optional)
  st.write("Extracted text from the PDF:")
  st.text_area("Full Text", full_text, height=300)

  # Generate summary
  def extractive_summary(text, num_sentences):
    stop_words = set(stopwords.words('english'))
    words = word_tokenize(full_text.lower())
    words = [word for word in words if word.isalnum() and word not in stop_words]

    fdist = FreqDist(words)

    sentences = sent_tokenize(full_text)
    sentence_scores = {}

    for sentence in sentences:
      for word in word_tokenize(sentence.lower()):
        if word in fdist:
          if sentence not in sentence_scores:
            sentence_scores[sentence] = fdist[word]
          else:
            sentence_scores[sentence] += fdist[word]
    summary_sentences = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)
    summary = ' '.join(summary_sentences)
    return summary
  # Display the summary
  st.write("Summary of the PDF:")
  summary = extractive_summary(full_text,10)
  st.write(summary)

# Provide additional instructions or information
st.write("Please upload a PDF file to see its summary.")
